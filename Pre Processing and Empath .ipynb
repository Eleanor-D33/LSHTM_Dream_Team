{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources used for pre-processing \n",
    "\n",
    "- https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove URLs from the tweets\n",
    "* Tokenize text\n",
    "* Remove emails\n",
    "* Remove new lines characters\n",
    "* Remove distracting single quotes\n",
    "* Remove all punctuation signs\n",
    "* Lowercase all text\n",
    "* Detokenize text\n",
    "* Convert list of texts to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# pip -- install nltk \n",
    "\n",
    "# Importing relevant libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tw_date</th>\n",
       "      <th>place_id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356026121549131779</td>\n",
       "      <td>It’s National Storytelling Week -&amp;amp; we all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:46:35.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>00486f39ae8bd30d</td>\n",
       "      <td>Ilford, London</td>\n",
       "      <td>Ilford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1356015933110673412</td>\n",
       "      <td>@blue_notorious That's a really clever way to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:06:06.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>519618c33762168f</td>\n",
       "      <td>South Shore, England</td>\n",
       "      <td>South Shore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1355998497649078275</td>\n",
       "      <td>Personal view. Banning leafletting is a nonsen...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:56:49.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>4b6c0ea1297b258a</td>\n",
       "      <td>Leyland, England</td>\n",
       "      <td>Leyland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1355985193128112134</td>\n",
       "      <td>Trophy Hunters: this is one.of the very rare t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:03:57.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>22611f9e4155fb8c</td>\n",
       "      <td>Crewkerne, England</td>\n",
       "      <td>Crewkerne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1355979822623825920</td>\n",
       "      <td>@LycanEclipse Its not stupid. But I know what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T20:42:37.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>42d0cf7d49d27c95</td>\n",
       "      <td>Hillingdon, London</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002</th>\n",
       "      <td>1349332515488722945</td>\n",
       "      <td>@angiebUK @LTHlondon @JuliaHB1 Why? He's perfe...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-13T12:28:35.000Z</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>2d41dd150edf488a</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>Weston-super-Mare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003</th>\n",
       "      <td>1349321013478232065</td>\n",
       "      <td>Shut, and I cannot stress this next part enoug...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-13T11:42:53.000Z</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>573ede7f6c450804</td>\n",
       "      <td>Brighton, England</td>\n",
       "      <td>Brighton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107004</th>\n",
       "      <td>1349284431111057409</td>\n",
       "      <td>Eavesdropping on school assembly my daughter’s...</td>\n",
       "      <td>1</td>\n",
       "      <td>MentalHealthAwareness</td>\n",
       "      <td>2021-01-13T09:17:31.000Z</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>493d127fe5461353</td>\n",
       "      <td>Upper Quinton, England</td>\n",
       "      <td>Upper Quinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107005</th>\n",
       "      <td>1349282649383161856</td>\n",
       "      <td>Likely stress point is Russia - Western relati...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-13T09:10:26.000Z</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>4393349f368f67a1</td>\n",
       "      <td>Lambeth, London</td>\n",
       "      <td>Lambeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107006</th>\n",
       "      <td>1349270443694436358</td>\n",
       "      <td>@zola_jfk @A_B_Jones @jamestorry @KDDoran @kat...</td>\n",
       "      <td>2</td>\n",
       "      <td>livebetterMcr,musictherapy</td>\n",
       "      <td>2021-01-13T08:21:56.000Z</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>37885fe8bf29ccab</td>\n",
       "      <td>Marple, England</td>\n",
       "      <td>Marple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107007 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0       1356026121549131779   \n",
       "1       1356015933110673412   \n",
       "2       1355998497649078275   \n",
       "3       1355985193128112134   \n",
       "4       1355979822623825920   \n",
       "...                     ...   \n",
       "107002  1349332515488722945   \n",
       "107003  1349321013478232065   \n",
       "107004  1349284431111057409   \n",
       "107005  1349282649383161856   \n",
       "107006  1349270443694436358   \n",
       "\n",
       "                                                     text  hashtags_cnt  \\\n",
       "0       It’s National Storytelling Week -&amp; we all ...             0   \n",
       "1       @blue_notorious That's a really clever way to ...             0   \n",
       "2       Personal view. Banning leafletting is a nonsen...             0   \n",
       "3       Trophy Hunters: this is one.of the very rare t...             0   \n",
       "4       @LycanEclipse Its not stupid. But I know what ...             0   \n",
       "...                                                   ...           ...   \n",
       "107002  @angiebUK @LTHlondon @JuliaHB1 Why? He's perfe...             0   \n",
       "107003  Shut, and I cannot stress this next part enoug...             0   \n",
       "107004  Eavesdropping on school assembly my daughter’s...             1   \n",
       "107005  Likely stress point is Russia - Western relati...             0   \n",
       "107006  @zola_jfk @A_B_Jones @jamestorry @KDDoran @kat...             2   \n",
       "\n",
       "                          hashtags                created_at     tw_date  \\\n",
       "0                              NaN  2021-01-31T23:46:35.000Z  2021-01-31   \n",
       "1                              NaN  2021-01-31T23:06:06.000Z  2021-01-31   \n",
       "2                              NaN  2021-01-31T21:56:49.000Z  2021-01-31   \n",
       "3                              NaN  2021-01-31T21:03:57.000Z  2021-01-31   \n",
       "4                              NaN  2021-01-31T20:42:37.000Z  2021-01-31   \n",
       "...                            ...                       ...         ...   \n",
       "107002                         NaN  2021-01-13T12:28:35.000Z  2021-01-13   \n",
       "107003                         NaN  2021-01-13T11:42:53.000Z  2021-01-13   \n",
       "107004       MentalHealthAwareness  2021-01-13T09:17:31.000Z  2021-01-13   \n",
       "107005                         NaN  2021-01-13T09:10:26.000Z  2021-01-13   \n",
       "107006  livebetterMcr,musictherapy  2021-01-13T08:21:56.000Z  2021-01-13   \n",
       "\n",
       "                place_id                   full_name               name  \n",
       "0       00486f39ae8bd30d              Ilford, London             Ilford  \n",
       "1       519618c33762168f        South Shore, England        South Shore  \n",
       "2       4b6c0ea1297b258a            Leyland, England            Leyland  \n",
       "3       22611f9e4155fb8c          Crewkerne, England          Crewkerne  \n",
       "4       42d0cf7d49d27c95          Hillingdon, London         Hillingdon  \n",
       "...                  ...                         ...                ...  \n",
       "107002  2d41dd150edf488a  Weston-super-Mare, England  Weston-super-Mare  \n",
       "107003  573ede7f6c450804           Brighton, England           Brighton  \n",
       "107004  493d127fe5461353      Upper Quinton, England      Upper Quinton  \n",
       "107005  4393349f368f67a1             Lambeth, London            Lambeth  \n",
       "107006  37885fe8bf29ccab             Marple, England             Marple  \n",
       "\n",
       "[107007 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data \n",
    "\n",
    "tweet_text = pd.read_csv('/Users/eleanordavies/Desktop/Sample_twitterdata_05Feb2021.csv')\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to remove characters \n",
    "\n",
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "#Splitting twtter data text column to list\n",
    "data_to_list = tweet_text['text'].values.tolist()\n",
    "\n",
    "#applying the above function \n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "\n",
    "# tempdf = pd.DataFrame(temp)\n",
    "# tempdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['it', 'national', 'storytelling', 'week', 'amp', 'we', 'all', 'have', 'story', 'to', 'tell', 'story', 'to', 'share', 'story', 'to', 'hear', 'let', 'use', 'our', 'stories', 'to', 'connect', 'with', 'each', 'other', 'to', 'enhance', 'listening', 'language', 'amp', 'communication', 'to', 'release', 'stress', 'to', 'empathise', 'amp', 'understand', 'each', 'other', 'it', 'all', 'about', 'our', 'story'], ['thats', 'really', 'clever', 'way', 'to', 'get', 'look', 'at', 'the', 'characters', 'hopefully', 'its', 'helped', 'with', 'the', 'anxiety'], ['personal', 'view', 'banning', 'leafletting', 'is', 'nonsensical', 'over', 'reaction', 'could', 'be', 'part', 'of', 'my', 'daily', 'exercise', 'and', 'wouldnt', 'be', 'harming', 'anyone'], ['trophy', 'hunters', 'this', 'is', 'one', 'of', 'the', 'very', 'rare', 'times', 'wish', 'we', 'had', 'capital', 'punishment', 'in', 'gb', 'people', 'who', 'exercise', 'this', 'fun', 'sport', 'do', 'not', 'deserve', 'to', 'exist', 'on', 'this', 'planet'], ['its', 'not', 'stupid', 'but', 'know', 'what', 'you', 'mean', 'thoughs', 'craft', 'ideas', 'youre', 'suddenly', 'itching', 'to', 'do', 'regardless', 'of', 'the', 'stress', 'and', 'time', 'they', 'just', 'gotta', 'be', 'done'], ['this', 'is', 'actually', 'fucking', 'dreadful', 'giving', 'me', 'anxiety', 'watching', 'this', 'showered', 'of', 'shite'], ['raleigh', 'tuff', 'burner', 'changed', 'my', 'life', 'was', 'never', 'interested', 'in', 'any', 'form', 'of', 'exercise', 'before', 'that', 'bmx', 'was', 'something', 'was', 'relatively', 'good', 'at', 'and', 'loved', 'it'], ['my', 'activity', 'rings', 'tell', 'the', 'story', 'of', 'january', 'with', 'spot', 'of', 'covid', 'as', 'someone', 'who', 'does', 'no', 'exercise', 'pleased', 'to', 'have', 'done', 'as', 'much', 'as', 'have'], ['long', 'slow', 'muddy', 'amp', 'hilly', 'run', 'today', 'after', 'chunky', 'upper', 'body', 'amp', 'core', 'workout', 'could', 'have', 'slobbed', 'on', 'the', 'sofa', 'til', 'supper', 'time', 'but', 'instead', 'made', 'serving', 'lasagnas', 'for', 'those', 'hour', 'days', 'when', 'cooking', 'fm', 'scratch', 'just', 'wont', 'happen', 'eating', 'amp', 'exercise', 'my', 'two', 'favourite', 'hobbies'], ['my', 'skin', 'aged', 'like', 'no', 'time', 'before', 'during', 'lockdown', 'stress', 'worries', 'ad', 'nauseaum', 'seem', 'to', 'have', 'succeeded', 'doing', 'year', 'job', 'in', 'months']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and removal all punctation, emojis and puts text into lowercase \n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detokenise returns them back into a sentence \n",
    "\n",
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it national storytelling week amp we all have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thats really clever way to get look at the cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personal view banning leafletting is nonsensic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trophy hunters this is one of the very rare ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its not stupid but know what you mean thoughs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002</th>\n",
       "      <td>why hes perfectly correct gov advice is only e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003</th>\n",
       "      <td>shut and cannot stress this next part enough t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107004</th>\n",
       "      <td>eavesdropping on school assembly my daughter s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107005</th>\n",
       "      <td>likely stress point is russia western relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107006</th>\n",
       "      <td>cheers john daily exercise no excuses music th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107007 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       it national storytelling week amp we all have ...\n",
       "1       thats really clever way to get look at the cha...\n",
       "2       personal view banning leafletting is nonsensic...\n",
       "3       trophy hunters this is one of the very rare ti...\n",
       "4       its not stupid but know what you mean thoughs ...\n",
       "...                                                   ...\n",
       "107002  why hes perfectly correct gov advice is only e...\n",
       "107003  shut and cannot stress this next part enough t...\n",
       "107004  eavesdropping on school assembly my daughter s...\n",
       "107005  likely stress point is russia western relation...\n",
       "107006  cheers john daily exercise no excuses music th...\n",
       "\n",
       "[107007 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_detoken = []\n",
    "for i in range(len(data_words)):\n",
    "    data_detoken.append(detokenize(data_words[i]))\n",
    "data_detoken = np.array(data_detoken)\n",
    "data_detoken_df = pd.DataFrame(data_detoken)\n",
    "data_detoken_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_detoken_df.to_csv('/Users/eleanordavies/Desktop/df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cleaned tweet text as column 'selected_tweets' to original dataframe \n",
    "frames = [data_detoken_df,tweet_text]\n",
    "demo_tweets_clean = pd.concat(frames, axis=1)\n",
    "\n",
    "demo_tweets_clean = demo_tweets_clean.rename(columns={0: \"selected_tweets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets Clean!\n"
     ]
    }
   ],
   "source": [
    "# Exporting the cleaned tweets to local directory \n",
    "\n",
    "# demo_tweets_clean.to_csv('/Users/eleanordavies/Desktop/demo_tweets_clean.csv', index = False)\n",
    "print(\"Tweets Clean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tw_date</th>\n",
       "      <th>place_id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it national storytelling week amp we all have ...</td>\n",
       "      <td>1356026121549131779</td>\n",
       "      <td>It’s National Storytelling Week -&amp;amp; we all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:46:35.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>00486f39ae8bd30d</td>\n",
       "      <td>Ilford, London</td>\n",
       "      <td>Ilford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thats really clever way to get look at the cha...</td>\n",
       "      <td>1356015933110673412</td>\n",
       "      <td>@blue_notorious That's a really clever way to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:06:06.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>519618c33762168f</td>\n",
       "      <td>South Shore, England</td>\n",
       "      <td>South Shore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personal view banning leafletting is nonsensic...</td>\n",
       "      <td>1355998497649078275</td>\n",
       "      <td>Personal view. Banning leafletting is a nonsen...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:56:49.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>4b6c0ea1297b258a</td>\n",
       "      <td>Leyland, England</td>\n",
       "      <td>Leyland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trophy hunters this is one of the very rare ti...</td>\n",
       "      <td>1355985193128112134</td>\n",
       "      <td>Trophy Hunters: this is one.of the very rare t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:03:57.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>22611f9e4155fb8c</td>\n",
       "      <td>Crewkerne, England</td>\n",
       "      <td>Crewkerne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its not stupid but know what you mean thoughs ...</td>\n",
       "      <td>1355979822623825920</td>\n",
       "      <td>@LycanEclipse Its not stupid. But I know what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T20:42:37.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>42d0cf7d49d27c95</td>\n",
       "      <td>Hillingdon, London</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     selected_tweets                   id  \\\n",
       "0  it national storytelling week amp we all have ...  1356026121549131779   \n",
       "1  thats really clever way to get look at the cha...  1356015933110673412   \n",
       "2  personal view banning leafletting is nonsensic...  1355998497649078275   \n",
       "3  trophy hunters this is one of the very rare ti...  1355985193128112134   \n",
       "4  its not stupid but know what you mean thoughs ...  1355979822623825920   \n",
       "\n",
       "                                                text  hashtags_cnt hashtags  \\\n",
       "0  It’s National Storytelling Week -&amp; we all ...             0      NaN   \n",
       "1  @blue_notorious That's a really clever way to ...             0      NaN   \n",
       "2  Personal view. Banning leafletting is a nonsen...             0      NaN   \n",
       "3  Trophy Hunters: this is one.of the very rare t...             0      NaN   \n",
       "4  @LycanEclipse Its not stupid. But I know what ...             0      NaN   \n",
       "\n",
       "                 created_at     tw_date          place_id  \\\n",
       "0  2021-01-31T23:46:35.000Z  2021-01-31  00486f39ae8bd30d   \n",
       "1  2021-01-31T23:06:06.000Z  2021-01-31  519618c33762168f   \n",
       "2  2021-01-31T21:56:49.000Z  2021-01-31  4b6c0ea1297b258a   \n",
       "3  2021-01-31T21:03:57.000Z  2021-01-31  22611f9e4155fb8c   \n",
       "4  2021-01-31T20:42:37.000Z  2021-01-31  42d0cf7d49d27c95   \n",
       "\n",
       "              full_name         name  \n",
       "0        Ilford, London       Ilford  \n",
       "1  South Shore, England  South Shore  \n",
       "2      Leyland, England      Leyland  \n",
       "3    Crewkerne, England    Crewkerne  \n",
       "4    Hillingdon, London   Hillingdon  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empath \n",
    "\n",
    "## Empath Resources \n",
    "\n",
    "- https://github.com/Ejhfast/empath-client\n",
    "- https://www.tandfonline.com/doi/abs/10.1080/09638237.2020.1739251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import empath\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from empath import Empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lexicon object \n",
    "# list of categories within empath \n",
    "lexicon = Empath()\n",
    "list_cat = ['help', 'office', 'dance', 'money', 'wedding', 'domestic_work', 'sleep', 'medical_emergency', 'cold', 'hate', 'cheerfulness', 'aggression', 'occupation', 'envy', 'anticipation', 'family', 'vacation', 'crime', 'attractive', 'masculine', 'prison', 'health', 'pride', 'dispute', 'nervousness', 'government', 'weakness', 'horror', 'swearing_terms', 'leisure', 'suffering', 'royalty', 'wealthy', 'tourism', 'furniture', 'school', 'magic', 'beach', 'journalism', 'morning', 'banking', 'social_media', 'exercise', 'night', 'kill', 'blue_collar_job', 'art', 'ridicule', 'play', 'computer', 'college', 'optimism', 'stealing', 'real_estate', 'home', 'divine', 'sexual', 'fear', 'irritability', 'superhero', 'business', 'driving', 'pet', 'childish', 'cooking', 'exasperation', 'religion', 'hipster', 'internet', 'surprise', 'reading', 'worship', 'leader', 'independence', 'movement', 'body', 'noise', 'eating', 'medieval', 'zest', 'confusion', 'water', 'sports', 'death', 'healing', 'legend', 'heroic', 'celebration', 'restaurant', 'violence', 'programming', 'dominant_heirarchical', 'military', 'neglect', 'swimming', 'exotic', 'love', 'hiking', 'communication', 'hearing', 'order', 'sympathy', 'hygiene', 'weather', 'anonymity', 'trust', 'ancient', 'deception', 'fabric', 'air_travel', 'fight', 'dominant_personality', 'music', 'vehicle', 'politeness', 'toy', 'farming', 'meeting', 'war', 'speaking', 'listen', 'urban', 'shopping', 'disgust', 'fire', 'tool', 'phone', 'gain', 'sound', 'injury', 'sailing', 'rage', 'science', 'work', 'appearance', 'valuable', 'warmth', 'youth', 'sadness', 'fun', 'emotional', 'joy', 'affection', 'traveling', 'fashion', 'ugliness', 'lust', 'shame', 'torment', 'economics', 'anger', 'politics', 'ship', 'clothing', 'car', 'strength', 'technology', 'breaking', 'shape_and_size', 'power', 'white_collar_job', 'animal', 'party', 'terrorism', 'smell', 'disappointment', 'poor', 'plant', 'pain', 'beauty', 'timidity', 'philosophy', 'negotiate', 'negative_emotion', 'cleaning', 'messaging', 'competing', 'law', 'friends', 'payment', 'achievement', 'alcohol', 'liquid', 'feminine', 'weapon', 'children', 'monster', 'ocean', 'giving', 'contentment', 'writing', 'rural', 'positive_emotion', 'musical', 'colors', 'id', 'injury and death', 'demo', 'what']\n",
    "\n",
    "pos_cat = [\"worship\", \"masculine\", \"death\", \"weakness\", \"divine\", \"religion\", \"sleep\", \"swearing_terms\", \"injury\", \"envy\"]\n",
    "neg_cat = [\"gain\", \"reading\", \"banking\", \"independence\", \"programming\", \"payment\", \"technology\", \"tourism\", \"air_travel\", \"negotiate\"]\n",
    "tot_cat = pos_cat + neg_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to analyse sentences \n",
    "# can be altered to add category and normalise values \n",
    "# may need to specifiy categories \n",
    "\n",
    "def empath_analyse(sentence):\n",
    "    x = lexicon.analyze(sentence, categories=tot_cat)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tweets through empath \n",
    "- Create an array of the 'cleaned' text from the tweets \n",
    "- Run a for loop to analyse tweets usinh emapth_analyse function \n",
    "- Convert data dictionary into dataframe  \n",
    "- Append data dictionary dataframe to the exsiting tweet dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_list = demo_tweets_clean['selected_tweets'].values.tolist()\n",
    "data_to_list = np.array(data_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worship</th>\n",
       "      <th>masculine</th>\n",
       "      <th>death</th>\n",
       "      <th>weakness</th>\n",
       "      <th>divine</th>\n",
       "      <th>religion</th>\n",
       "      <th>sleep</th>\n",
       "      <th>swearing_terms</th>\n",
       "      <th>injury</th>\n",
       "      <th>envy</th>\n",
       "      <th>gain</th>\n",
       "      <th>reading</th>\n",
       "      <th>banking</th>\n",
       "      <th>independence</th>\n",
       "      <th>programming</th>\n",
       "      <th>payment</th>\n",
       "      <th>technology</th>\n",
       "      <th>tourism</th>\n",
       "      <th>air_travel</th>\n",
       "      <th>negotiate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worship  masculine  death  weakness  divine  religion  sleep  \\\n",
       "0      0.0        0.0    0.0       0.0     0.0       0.0    0.0   \n",
       "1      0.0        0.0    0.0       0.0     0.0       0.0    0.0   \n",
       "2      0.0        0.0    0.0       0.0     0.0       0.0    0.0   \n",
       "3      0.0        0.0    1.0       0.0     0.0       0.0    0.0   \n",
       "4      0.0        0.0    0.0       0.0     0.0       0.0    0.0   \n",
       "\n",
       "   swearing_terms  injury  envy  gain  reading  banking  independence  \\\n",
       "0             0.0     0.0   0.0   0.0      4.0      0.0           0.0   \n",
       "1             0.0     0.0   0.0   0.0      0.0      0.0           0.0   \n",
       "2             0.0     0.0   0.0   0.0      0.0      0.0           0.0   \n",
       "3             0.0     0.0   0.0   0.0      0.0      0.0           0.0   \n",
       "4             0.0     1.0   0.0   0.0      1.0      0.0           0.0   \n",
       "\n",
       "   programming  payment  technology  tourism  air_travel  negotiate  \n",
       "0          0.0      0.0         1.0      0.0         0.0        0.0  \n",
       "1          0.0      0.0         0.0      0.0         0.0        0.0  \n",
       "2          0.0      0.0         0.0      0.0         0.0        0.0  \n",
       "3          0.0      0.0         0.0      0.0         0.0        0.0  \n",
       "4          0.0      0.0         0.0      0.0         0.0        0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =[]\n",
    "for i in range(len(data_to_list)):\n",
    "    data.append(empath_analyse(data_to_list[i])),\n",
    "data_dict = pd.DataFrame.from_dict(data)\n",
    "data_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emapth Analysis Complete!\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([demo_tweets_clean, data_dict], axis=1, join=\"inner\")\n",
    "print(\"Emapth Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tw_date</th>\n",
       "      <th>place_id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>gain</th>\n",
       "      <th>reading</th>\n",
       "      <th>banking</th>\n",
       "      <th>independence</th>\n",
       "      <th>programming</th>\n",
       "      <th>payment</th>\n",
       "      <th>technology</th>\n",
       "      <th>tourism</th>\n",
       "      <th>air_travel</th>\n",
       "      <th>negotiate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it national storytelling week amp we all have ...</td>\n",
       "      <td>1356026121549131779</td>\n",
       "      <td>It’s National Storytelling Week -&amp;amp; we all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:46:35.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>00486f39ae8bd30d</td>\n",
       "      <td>Ilford, London</td>\n",
       "      <td>Ilford</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thats really clever way to get look at the cha...</td>\n",
       "      <td>1356015933110673412</td>\n",
       "      <td>@blue_notorious That's a really clever way to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T23:06:06.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>519618c33762168f</td>\n",
       "      <td>South Shore, England</td>\n",
       "      <td>South Shore</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personal view banning leafletting is nonsensic...</td>\n",
       "      <td>1355998497649078275</td>\n",
       "      <td>Personal view. Banning leafletting is a nonsen...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:56:49.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>4b6c0ea1297b258a</td>\n",
       "      <td>Leyland, England</td>\n",
       "      <td>Leyland</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trophy hunters this is one of the very rare ti...</td>\n",
       "      <td>1355985193128112134</td>\n",
       "      <td>Trophy Hunters: this is one.of the very rare t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T21:03:57.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>22611f9e4155fb8c</td>\n",
       "      <td>Crewkerne, England</td>\n",
       "      <td>Crewkerne</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its not stupid but know what you mean thoughs ...</td>\n",
       "      <td>1355979822623825920</td>\n",
       "      <td>@LycanEclipse Its not stupid. But I know what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-31T20:42:37.000Z</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>42d0cf7d49d27c95</td>\n",
       "      <td>Hillingdon, London</td>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     selected_tweets                   id  \\\n",
       "0  it national storytelling week amp we all have ...  1356026121549131779   \n",
       "1  thats really clever way to get look at the cha...  1356015933110673412   \n",
       "2  personal view banning leafletting is nonsensic...  1355998497649078275   \n",
       "3  trophy hunters this is one of the very rare ti...  1355985193128112134   \n",
       "4  its not stupid but know what you mean thoughs ...  1355979822623825920   \n",
       "\n",
       "                                                text  hashtags_cnt hashtags  \\\n",
       "0  It’s National Storytelling Week -&amp; we all ...             0      NaN   \n",
       "1  @blue_notorious That's a really clever way to ...             0      NaN   \n",
       "2  Personal view. Banning leafletting is a nonsen...             0      NaN   \n",
       "3  Trophy Hunters: this is one.of the very rare t...             0      NaN   \n",
       "4  @LycanEclipse Its not stupid. But I know what ...             0      NaN   \n",
       "\n",
       "                 created_at     tw_date          place_id  \\\n",
       "0  2021-01-31T23:46:35.000Z  2021-01-31  00486f39ae8bd30d   \n",
       "1  2021-01-31T23:06:06.000Z  2021-01-31  519618c33762168f   \n",
       "2  2021-01-31T21:56:49.000Z  2021-01-31  4b6c0ea1297b258a   \n",
       "3  2021-01-31T21:03:57.000Z  2021-01-31  22611f9e4155fb8c   \n",
       "4  2021-01-31T20:42:37.000Z  2021-01-31  42d0cf7d49d27c95   \n",
       "\n",
       "              full_name         name  ...  gain  reading  banking  \\\n",
       "0        Ilford, London       Ilford  ...   0.0      4.0      0.0   \n",
       "1  South Shore, England  South Shore  ...   0.0      0.0      0.0   \n",
       "2      Leyland, England      Leyland  ...   0.0      0.0      0.0   \n",
       "3    Crewkerne, England    Crewkerne  ...   0.0      0.0      0.0   \n",
       "4    Hillingdon, London   Hillingdon  ...   0.0      1.0      0.0   \n",
       "\n",
       "   independence  programming  payment  technology  tourism  air_travel  \\\n",
       "0           0.0          0.0      0.0         1.0      0.0         0.0   \n",
       "1           0.0          0.0      0.0         0.0      0.0         0.0   \n",
       "2           0.0          0.0      0.0         0.0      0.0         0.0   \n",
       "3           0.0          0.0      0.0         0.0      0.0         0.0   \n",
       "4           0.0          0.0      0.0         0.0      0.0         0.0   \n",
       "\n",
       "   negotiate  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result[\"id\"] = result.index\n",
    "# saving non aggregated dataset of empath analysed tweets \n",
    "result.to_csv('/Users/eleanordavies/Desktop/results.csv', index = False) \n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_date</th>\n",
       "      <th>count_of_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tw_date  count_of_tweets\n",
       "0  2019-01-01               18\n",
       "1  2019-01-02               20\n",
       "2  2019-01-03               13\n",
       "3  2019-01-04               30\n",
       "4  2019-01-05               17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting total number of tweets per date \n",
    "\n",
    "pivot_table = result.pivot_table(\n",
    "     index='tw_date',\n",
    "     values='id',\n",
    "     aggfunc= len).reset_index()\n",
    "\n",
    "pivot_table.columns = ['tw_date','count_of_tweets']\n",
    "\n",
    "pivot_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_date</th>\n",
       "      <th>air_travel</th>\n",
       "      <th>banking</th>\n",
       "      <th>death</th>\n",
       "      <th>divine</th>\n",
       "      <th>envy</th>\n",
       "      <th>gain</th>\n",
       "      <th>independence</th>\n",
       "      <th>injury</th>\n",
       "      <th>masculine</th>\n",
       "      <th>...</th>\n",
       "      <th>payment</th>\n",
       "      <th>programming</th>\n",
       "      <th>reading</th>\n",
       "      <th>religion</th>\n",
       "      <th>sleep</th>\n",
       "      <th>swearing_terms</th>\n",
       "      <th>technology</th>\n",
       "      <th>tourism</th>\n",
       "      <th>weakness</th>\n",
       "      <th>worship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.138122</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.020979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.299401</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.005988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tw_date  air_travel   banking     death    divine      envy      gain  \\\n",
       "0    2019-01-01    0.111111  0.000000  0.333333  0.000000  0.000000  0.055556   \n",
       "1    2019-01-02    0.000000  0.000000  0.100000  0.000000  0.000000  0.100000   \n",
       "2    2019-01-03    0.000000  0.076923  0.230769  0.000000  0.076923  0.076923   \n",
       "3    2019-01-04    0.000000  0.000000  0.000000  0.200000  0.000000  0.000000   \n",
       "4    2019-01-05    0.000000  0.000000  0.294118  0.117647  0.058824  0.000000   \n",
       "..          ...         ...       ...       ...       ...       ...       ...   \n",
       "757  2021-01-27    0.044199  0.066298  0.237569  0.022099  0.022099  0.016575   \n",
       "758  2021-01-28    0.028986  0.086957  0.202899  0.014493  0.007246  0.057971   \n",
       "759  2021-01-29    0.030864  0.012346  0.154321  0.018519  0.006173  0.061728   \n",
       "760  2021-01-30    0.048951  0.027972  0.125874  0.013986  0.006993  0.034965   \n",
       "761  2021-01-31    0.029940  0.053892  0.299401  0.011976  0.029940  0.041916   \n",
       "\n",
       "     independence    injury  masculine  ...   payment  programming   reading  \\\n",
       "0        0.111111  0.111111   0.000000  ...  0.000000     0.111111  0.055556   \n",
       "1        0.000000  0.300000   0.000000  ...  0.000000     0.100000  0.150000   \n",
       "2        0.000000  0.384615   0.000000  ...  0.153846     0.000000  0.000000   \n",
       "3        0.000000  0.066667   0.066667  ...  0.000000     0.000000  0.100000   \n",
       "4        0.000000  0.470588   0.000000  ...  0.000000     0.000000  0.058824   \n",
       "..            ...       ...        ...  ...       ...          ...       ...   \n",
       "757      0.038674  0.193370   0.022099  ...  0.088398     0.044199  0.088398   \n",
       "758      0.021739  0.289855   0.036232  ...  0.101449     0.014493  0.137681   \n",
       "759      0.012346  0.216049   0.012346  ...  0.018519     0.061728  0.086420   \n",
       "760      0.013986  0.174825   0.020979  ...  0.006993     0.034965  0.076923   \n",
       "761      0.029940  0.233533   0.029940  ...  0.023952     0.029940  0.149701   \n",
       "\n",
       "     religion     sleep  swearing_terms  technology   tourism  weakness  \\\n",
       "0    0.000000  0.055556        0.000000    0.111111  0.000000  0.000000   \n",
       "1    0.000000  0.100000        0.000000    0.300000  0.000000  0.000000   \n",
       "2    0.000000  0.000000        0.000000    0.000000  0.000000  0.153846   \n",
       "3    0.033333  0.166667        0.000000    0.000000  0.033333  0.000000   \n",
       "4    0.117647  0.411765        0.000000    0.000000  0.058824  0.294118   \n",
       "..        ...       ...             ...         ...       ...       ...   \n",
       "757  0.060773  0.138122        0.022099    0.071823  0.033149  0.049724   \n",
       "758  0.028986  0.050725        0.043478    0.065217  0.007246  0.043478   \n",
       "759  0.012346  0.240741        0.012346    0.080247  0.018519  0.074074   \n",
       "760  0.013986  0.216783        0.020979    0.027972  0.034965  0.027972   \n",
       "761  0.011976  0.095808        0.095808    0.083832  0.035928  0.017964   \n",
       "\n",
       "      worship  \n",
       "0    0.111111  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.117647  \n",
       "..        ...  \n",
       "757  0.033149  \n",
       "758  0.014493  \n",
       "759  0.006173  \n",
       "760  0.020979  \n",
       "761  0.005988  \n",
       "\n",
       "[762 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating data by date and get mean of lexical categories \n",
    "\n",
    "mean_pivot_table = result.pivot_table(\n",
    "    index=[ \"tw_date\"], # \"name\"], \n",
    "    values=tot_cat,\n",
    "    aggfunc=np.mean).reset_index()\n",
    "mean_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pivot_table['count'] = mean_pivot_table.tw_date.map(\n",
    "   pivot_table.set_index('tw_date').count_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_date</th>\n",
       "      <th>air_travel</th>\n",
       "      <th>banking</th>\n",
       "      <th>death</th>\n",
       "      <th>divine</th>\n",
       "      <th>envy</th>\n",
       "      <th>gain</th>\n",
       "      <th>independence</th>\n",
       "      <th>injury</th>\n",
       "      <th>masculine</th>\n",
       "      <th>...</th>\n",
       "      <th>programming</th>\n",
       "      <th>reading</th>\n",
       "      <th>religion</th>\n",
       "      <th>sleep</th>\n",
       "      <th>swearing_terms</th>\n",
       "      <th>technology</th>\n",
       "      <th>tourism</th>\n",
       "      <th>weakness</th>\n",
       "      <th>worship</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.138122</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.299401</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tw_date  air_travel   banking     death    divine      envy      gain  \\\n",
       "0    2019-01-01    0.111111  0.000000  0.333333  0.000000  0.000000  0.055556   \n",
       "1    2019-01-02    0.000000  0.000000  0.100000  0.000000  0.000000  0.100000   \n",
       "2    2019-01-03    0.000000  0.076923  0.230769  0.000000  0.076923  0.076923   \n",
       "3    2019-01-04    0.000000  0.000000  0.000000  0.200000  0.000000  0.000000   \n",
       "4    2019-01-05    0.000000  0.000000  0.294118  0.117647  0.058824  0.000000   \n",
       "..          ...         ...       ...       ...       ...       ...       ...   \n",
       "757  2021-01-27    0.044199  0.066298  0.237569  0.022099  0.022099  0.016575   \n",
       "758  2021-01-28    0.028986  0.086957  0.202899  0.014493  0.007246  0.057971   \n",
       "759  2021-01-29    0.030864  0.012346  0.154321  0.018519  0.006173  0.061728   \n",
       "760  2021-01-30    0.048951  0.027972  0.125874  0.013986  0.006993  0.034965   \n",
       "761  2021-01-31    0.029940  0.053892  0.299401  0.011976  0.029940  0.041916   \n",
       "\n",
       "     independence    injury  masculine  ...  programming   reading  religion  \\\n",
       "0        0.111111  0.111111   0.000000  ...     0.111111  0.055556  0.000000   \n",
       "1        0.000000  0.300000   0.000000  ...     0.100000  0.150000  0.000000   \n",
       "2        0.000000  0.384615   0.000000  ...     0.000000  0.000000  0.000000   \n",
       "3        0.000000  0.066667   0.066667  ...     0.000000  0.100000  0.033333   \n",
       "4        0.000000  0.470588   0.000000  ...     0.000000  0.058824  0.117647   \n",
       "..            ...       ...        ...  ...          ...       ...       ...   \n",
       "757      0.038674  0.193370   0.022099  ...     0.044199  0.088398  0.060773   \n",
       "758      0.021739  0.289855   0.036232  ...     0.014493  0.137681  0.028986   \n",
       "759      0.012346  0.216049   0.012346  ...     0.061728  0.086420  0.012346   \n",
       "760      0.013986  0.174825   0.020979  ...     0.034965  0.076923  0.013986   \n",
       "761      0.029940  0.233533   0.029940  ...     0.029940  0.149701  0.011976   \n",
       "\n",
       "        sleep  swearing_terms  technology   tourism  weakness   worship  count  \n",
       "0    0.055556        0.000000    0.111111  0.000000  0.000000  0.111111     18  \n",
       "1    0.100000        0.000000    0.300000  0.000000  0.000000  0.000000     20  \n",
       "2    0.000000        0.000000    0.000000  0.000000  0.153846  0.000000     13  \n",
       "3    0.166667        0.000000    0.000000  0.033333  0.000000  0.000000     30  \n",
       "4    0.411765        0.000000    0.000000  0.058824  0.294118  0.117647     17  \n",
       "..        ...             ...         ...       ...       ...       ...    ...  \n",
       "757  0.138122        0.022099    0.071823  0.033149  0.049724  0.033149    181  \n",
       "758  0.050725        0.043478    0.065217  0.007246  0.043478  0.014493    138  \n",
       "759  0.240741        0.012346    0.080247  0.018519  0.074074  0.006173    162  \n",
       "760  0.216783        0.020979    0.027972  0.034965  0.027972  0.020979    143  \n",
       "761  0.095808        0.095808    0.083832  0.035928  0.017964  0.005988    167  \n",
       "\n",
       "[762 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pivot_table.to_csv('/Users/eleanordavies/Desktop/mean_pivot_table.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
